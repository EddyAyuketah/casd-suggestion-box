remember this was my original code. 

import os
import math
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path

# =============================================================================
# CONFIGURATION
# =============================================================================
OUTS_GOAL = 8000
QUARTER_GOAL = 95100
DEADLINE = datetime(2025, 12, 7, 23, 59, 59)
QUARTER_START = datetime(2025, 9, 6, 18, 0)
COMMIT_WW = 202549
SSAFI_LSB_OPERATION = 9812
SEGMENT_DAY_END = 104

# Look-ahead Configuration
LOOKAHEAD_HOURS = 30          # Hours to look ahead from PP (can be 24, 26, 30, etc.)
LAYER_COUNT_THRESHOLD = 0.30  # Minimum layer count to consider (exclude < 30%)
LIMITER_HAO_VARIANCE = 3.5    # Hours over CT_GOAL to flag as limiter
LIMITER_WSPW_GAP = 1000       # WSPW pace gap to flag as limiter

# 24/7 Operation Parameters
SHIFTS_PER_DAY = 2
HOURS_PER_SHIFT = 12
DAYS_PER_WEEK = 7

# Data paths
LINEVIEW_PATH = r"\\azshfs.intel.com\azanalysistop\AZAnalysis\1274_MAODATA\AZFSM_Production\COS_DB\Combined\LineView.TXT"
CEID_PATH = r"\\azshfs.intel.com\azanalysistop\AZAnalysis\1274_MAODATA\AZFSM_Production\COS_DB\Combined\CEID.TXT"
EXCLUDED_OPERATIONS = [204]

# =============================================================================
# HELPERS
# =============================================================================
def ceil_days(seconds: float) -> int:
    """Return ceiling of days from seconds, min 0."""
    return max(0, int(math.ceil(seconds / 86400.0)))

def round_up_days(n: float) -> int:
    """Round to whole days: positive rounds up, negative rounds to whole overdue days."""
    if n is None:
        return 0
    if n >= 0:
        return int(math.ceil(n))
    return -int(math.ceil(abs(n)))

def hours_until_next_monday(now: datetime) -> float:
    """Hours remaining until next Monday 00:00 local time."""
    next_mon = (now + timedelta(days=(7 - now.weekday()))).replace(hour=0, minute=0, second=0, microsecond=0)
    return max(0.0, (next_mon - now).total_seconds() / 3600.0)

def load_tsv(path: str) -> pd.DataFrame:
    p = Path(path)
    if not p.exists():
        raise FileNotFoundError(f"File not found: {path}")
    return pd.read_csv(p, sep="\t")

def fmt_int(x):
    try:
        if x is None or (isinstance(x, float) and (math.isnan(x) or math.isinf(x))):
            return "â€”"
        return f"{int(round(x)):,}"
    except Exception:
        return str(x)

def fmt_float(x, d=1):
    try:
        if x is None or (isinstance(x, float) and (math.isnan(x) or math.isinf(x))):
            return "â€”"
        return f"{x:,.{d}f}"
    except Exception:
        return str(x)

def safe_num(s, default=0.0):
    try:
        return float(s)
    except Exception:
        return default

# =============================================================================
# DB CONNECTOR
# =============================================================================
try:
    import PyUber
    _DB = None
    def get_db():
        global _DB
        if _DB is None:
            _DB = PyUber.connect('F32_PROD_XEUS')
        return _DB
except Exception:
    PyUber = None
    def get_db():
        raise RuntimeError("PyUber (internal DB connector) not available. Install/enable and rerun.")

# =============================================================================
# LOAD DATA
# =============================================================================
now = datetime.now()

df_lineview = load_tsv(LINEVIEW_PATH)
df_ceid = pd.read_csv(CEID_PATH, sep="\t") if Path(CEID_PATH).exists() else pd.DataFrame()

# Normalize columns we rely on
if "FULL_LOOP_SEQ" not in df_lineview or "OPERATION" not in df_lineview or "INV_PROD" not in df_lineview:
    missing = [c for c in ["FULL_LOOP_SEQ", "OPERATION", "INV_PROD"] if c not in df_lineview.columns]
    raise KeyError(f"LineView missing columns: {missing}")

df_lineview["FULL_LOOP_SEQ"] = pd.to_numeric(df_lineview["FULL_LOOP_SEQ"], errors="coerce")
df_lineview["INV_PROD"] = pd.to_numeric(df_lineview["INV_PROD"], errors="coerce").fillna(0.0)
if "SEGMENT_DAY" in df_lineview:
    df_lineview["SEGMENT_DAY"] = pd.to_numeric(df_lineview["SEGMENT_DAY"], errors="coerce").fillna(0).astype(int)
else:
    df_lineview["SEGMENT_DAY"] = 0

if not df_ceid.empty and "CEID" in df_ceid.columns:
    df_ceid["CEID"] = df_ceid["CEID"].astype(str)

# =============================================================================
# QUARTERLY SHIPMENTS (SQL)
# =============================================================================
db = get_db()
quarter_ships_sql = f'''
SELECT
  SUM(WAFER_QTY) as TOTAL_WAFERS,
  COUNT(DISTINCT LOT) as LOT_COUNT,
  MAX(OUT_DATE) as LAST_SHIP_DATE,
  MIN(OUT_DATE) as FIRST_SHIP_DATE
FROM
  F_LOT_RUN_CARD
WHERE
  OUT_DATE >= TO_DATE('{QUARTER_START.strftime("%m/%d/%Y %H:%M")}', 'MM/DD/YYYY HH24:MI')
  AND OUT_DATE <= SYSDATE
  AND LOT_TYPE IN ('PROD', 'ENG')
  AND LOT LIKE 'L%'
  AND LOT NOT LIKE 'L9%'
  AND OPERATION = {SSAFI_LSB_OPERATION}
  AND WAFER_QTY > 0
'''
qdf = pd.read_sql(quarter_ships_sql, db)

quarter_ships = safe_num(qdf['TOTAL_WAFERS'].iloc[0], 0.0)
lot_count = int(qdf['LOT_COUNT'].iloc[0] or 0)

first_ship = qdf['FIRST_SHIP_DATE'].iloc[0]
last_ship  = qdf['LAST_SHIP_DATE'].iloc[0]
if pd.isna(first_ship) or pd.isna(last_ship):
    actual_daily_rate = 0.0
    days_elapsed_actual = 0
else:
    first_ship = pd.to_datetime(first_ship)
    last_ship = pd.to_datetime(last_ship)
    days_elapsed_actual = max(1, (last_ship.normalize() - first_ship.normalize()).days + 1)
    actual_daily_rate = quarter_ships / days_elapsed_actual

# =============================================================================
# LAST WEEK SHIPMENTS
# =============================================================================
current_monday = (now - timedelta(days=now.weekday())).replace(hour=0, minute=0, second=0, microsecond=0)
last_monday = current_monday - timedelta(days=7)

last_week_sql = f'''
SELECT
  SUM(WAFER_QTY) as TOTAL_WAFERS
FROM
  F_LOT_RUN_CARD
WHERE
  OUT_DATE >= TO_DATE('{last_monday.strftime("%m/%d/%Y %H:%M")}', 'MM/DD/YYYY HH24:MI')
  AND OUT_DATE < TO_DATE('{current_monday.strftime("%m/%d/%Y %H:%M")}', 'MM/DD/YYYY HH24:MI')
  AND LOT_TYPE IN ('PROD', 'ENG')
  AND LOT LIKE 'L%'
  AND LOT NOT LIKE 'L9%'
  AND OPERATION = {SSAFI_LSB_OPERATION}
  AND WAFER_QTY > 0
'''
lwd = pd.read_sql(last_week_sql, db)
last_week_ships = safe_num(lwd['TOTAL_WAFERS'].iloc[0], 0.0)
last_ww = COMMIT_WW - 1

# =============================================================================
# GET SSAFI LSB FULL LOOP SEQUENCE
# =============================================================================
try:
    ssafi_lsb_fls = float(df_lineview.loc[df_lineview["OPERATION"] == SSAFI_LSB_OPERATION, "FULL_LOOP_SEQ"].values[0])
except Exception:
    raise ValueError(f"Operation {SSAFI_LSB_OPERATION} not found in LineView")

# =============================================================================
# QUARTERLY PP CALCULATION (restored & hardened)
# =============================================================================
def _safe_div_floor(a, b):
    if b is None or b <= 0:
        return np.nan
    return a // b

def _safe_mod(a, b):
    if b is None or b <= 0:
        return np.nan
    return a % b

quarter_outs_remaining = max(0.0, QUARTER_GOAL - quarter_ships)
commit_inventory_remaining = quarter_outs_remaining

# Slice to upstream flow (â‰¤ ship FLS), exclude unwanted ops, keep order ASC
quarter_volume = (
    df_lineview
    .query(f"FULL_LOOP_SEQ <= {ssafi_lsb_fls} & OPERATION not in {EXCLUDED_OPERATIONS}")
    .sort_values("FULL_LOOP_SEQ", ascending=True)
    .copy()
)

# Reverse cumulative WIP from row â†’ ship
quarter_volume["PP_INV"] = quarter_volume["INV_PROD"].iloc[::-1].cumsum()[::-1]

# Your original PP_W / PP_mod logic (guarded)
quarter_volume = quarter_volume.assign(
    PP_W = quarter_volume["PP_INV"].apply(lambda v: _safe_div_floor(v, quarter_outs_remaining)),
    PP_mod = quarter_volume["PP_INV"].apply(lambda v: _safe_mod(v, quarter_outs_remaining)),
)

# Choose PP as the LAST row where PP_W == 1 (furthest downstream crossing)
quarter_volume_pp = quarter_volume.query("PP_W == 1").tail(1)

# Bump inventory: remaining â€“ PP_mod of first row before crossing (PP_W == 0)
if quarter_outs_remaining > 0 and not quarter_volume.query("PP_W == 0").empty:
    quarter_bump_inv = quarter_outs_remaining - quarter_volume.query("PP_W == 0").head(1)["PP_mod"].values[0]
else:
    quarter_bump_inv = 0.0

# Fallback if thereâ€™s not enough WIP to meet remaining quarter goal
if quarter_volume_pp.empty:
    total_wip = float(quarter_volume["INV_PROD"].sum())
    print(f"\nâŒ CRITICAL: Insufficient WIP to meet quarterly goal!")
    print(f"   Total WIP: {total_wip:,.0f}w | Need: {quarter_outs_remaining:,.0f}w | Short: {quarter_outs_remaining - total_wip:,.0f}w")
    quarter_volume_pp = quarter_volume.tail(1)

# Extract PP fields (never zero unless truly zero)
pp_segment_day = int(quarter_volume_pp['SEGMENT_DAY'].values[0]) if 'SEGMENT_DAY' in quarter_volume_pp else 0
pp_full_loop_seq = float(quarter_volume_pp['FULL_LOOP_SEQ'].values[0]) if 'FULL_LOOP_SEQ' in quarter_volume_pp else 0.0

# =============================================================================
# TIME / SCHEDULE ANALYSIS (fixed)
# =============================================================================
# Calendar days remaining (ceil of seconds)
total_seconds_remaining = max(0.0, (DEADLINE - now).total_seconds())
calendar_days_remaining = ceil_days(total_seconds_remaining)

# Segment days remaining (exclusive) = SD_END - PP_SD
segment_days_remaining = max(0, SEGMENT_DAY_END - pp_segment_day)

# Ahead/Behind (rounded whole days) with status icon
commit_ahead_behind_days_raw = calendar_days_remaining - segment_days_remaining
commit_ahead_behind_days = round_up_days(commit_ahead_behind_days_raw)
commit_status_icon = "âœ“ AHEAD" if commit_ahead_behind_days >= 0 else "âŒ BEHIND"

# =============================================================================
# INVENTORY ANALYSIS (optional)
# =============================================================================
total_current_wip = df_lineview['INV_PROD'].sum()

if 'PW_OUTS_PROD' in df_lineview.columns:
    try:
        pw_outs = float(df_lineview.loc[df_lineview["OPERATION"] == SSAFI_LSB_OPERATION, "PW_OUTS_PROD"].values[0])
        last_24hr_inv_reduction = pw_outs / 7  # your original heuristic
    except Exception:
        last_24hr_inv_reduction = actual_daily_rate if actual_daily_rate else 0.0
else:
    last_24hr_inv_reduction = actual_daily_rate if actual_daily_rate else 0.0

# =============================================================================
# WEEKLY PP CALCULATION (kept as-is with guards)
# =============================================================================
if "CW_OUTS_PROD" in df_lineview.columns:
    try:
        current_week_outs = float(
            df_lineview.loc[df_lineview["OPERATION"] == SSAFI_LSB_OPERATION, "CW_OUTS_PROD"].values[0]
        )
    except Exception:
        current_week_outs = 0.0
else:
    current_week_outs = 0.0

last_week_shortfall = max(0.0, OUTS_GOAL - last_week_ships)
this_week_required = OUTS_GOAL + last_week_shortfall
outs_remaining_this_week = max(0.0, this_week_required - current_week_outs)

# PP for weekly target (your original pattern, guarded)
if this_week_required > 0:
    pp_week = (df_lineview
        .query(f"FULL_LOOP_SEQ <= {ssafi_lsb_fls} & OPERATION not in {EXCLUDED_OPERATIONS}")
        .filter(["SEGMENT_DAY", "OPERATION", "OPER_SHORT_DESC", "CEID", "INV_PROD", "FULL_LOOP_SEQ"])
        .assign(PP_INV=lambda x: x.iloc[::-1]['INV_PROD'].cumsum()[::-1],
                PP_W=lambda x: x["PP_INV"] // this_week_required,
                PP_mod=lambda x: x["PP_INV"] % this_week_required)
        .query("PP_W == 1 & INV_PROD != 0"))
    pp_operation = pp_week.query(f"PP_mod == {pp_week['PP_mod'].min()}") if not pp_week.empty else pd.DataFrame()

    pp_before = (df_lineview
        .query(f"FULL_LOOP_SEQ <= {ssafi_lsb_fls} & OPERATION not in {EXCLUDED_OPERATIONS}")
        .filter(["SEGMENT_DAY", "OPERATION", "OPER_SHORT_DESC", "CEID", "INV_PROD", "FULL_LOOP_SEQ"])
        .assign(PP_INV=lambda x: x.iloc[::-1]['INV_PROD'].cumsum()[::-1],
                PP_W=lambda x: x["PP_INV"] // this_week_required,
                PP_mod=lambda x: x["PP_INV"] % this_week_required)
        .query("PP_W == 0 & INV_PROD != 0"))
    bump_inv = this_week_required - pp_before["PP_INV"].head(1).values[0] if not pp_before.empty else 0.0
else:
    pp_operation = pd.DataFrame()
    bump_inv = 0.0

# =============================================================================
# REQUIRED RATES / WEEKLY NEEDS / PROJECTIONS
# =============================================================================
required_per_day = (quarter_outs_remaining / max(1, calendar_days_remaining)) if calendar_days_remaining else float('inf')
required_per_shift = required_per_day / max(1, SHIFTS_PER_DAY)
required_per_week = required_per_day * 7 if math.isfinite(required_per_day) else float('inf')

days_left_in_week = max(1, int(hours_until_next_monday(now) // 24))
hours_left_in_week = hours_until_next_monday(now)
shifts_left_in_week = max(1, int(hours_left_in_week // HOURS_PER_SHIFT))

this_week_per_shift = outs_remaining_this_week / max(1, shifts_left_in_week)
this_week_per_day = outs_remaining_this_week / max(1, days_left_in_week)

# Next week projection
days_into_week = now.weekday() + 1
current_week_daily_rate = (current_week_outs / max(1, days_into_week)) if current_week_outs else (actual_daily_rate or 0.0)
next_ww = COMMIT_WW + 1
next_ww_projected_ships = current_week_daily_rate * 7

# Rate analysis (informational vs required)
if actual_daily_rate and actual_daily_rate > 0:
    rate_gap = required_per_day - actual_daily_rate
    rate_gap_pct = (rate_gap / actual_daily_rate) * 100.0
    on_track = rate_gap <= 0
else:
    rate_gap = None
    rate_gap_pct = None
    on_track = None

# =============================================================================
# LOOK-AHEAD LIMITER ANALYSIS
# =============================================================================
print(f"\nðŸ” Analyzing {LOOKAHEAD_HOURS}h look-ahead from PP...")

# Get operations ahead of PP in the flow (to ship)
lookahead_ops = df_lineview.query(
    f"FULL_LOOP_SEQ > {pp_full_loop_seq} & FULL_LOOP_SEQ <= {ssafi_lsb_fls} & OPERATION not in {EXCLUDED_OPERATIONS}"
).copy()

# Filter by LAYER_COUNT threshold
if 'LAYER_COUNT' in lookahead_ops.columns:
    lookahead_ops = lookahead_ops.query(f"LAYER_COUNT >= {LAYER_COUNT_THRESHOLD}")
    print(f"  Filtered to operations with LAYER_COUNT >= {LAYER_COUNT_THRESHOLD}")

lookahead_ops = lookahead_ops.sort_values("FULL_LOOP_SEQ").copy()

# Calculate cumulative cycle time and window
if 'CT_GOAL' in lookahead_ops.columns:
    lookahead_ops['CT_GOAL'] = pd.to_numeric(lookahead_ops['CT_GOAL'], errors="coerce").fillna(0.0)
    lookahead_ops['CUMULATIVE_CT'] = lookahead_ops['CT_GOAL'].cumsum()
    lookahead_window = lookahead_ops.query(f"CUMULATIVE_CT <= {LOOKAHEAD_HOURS}").copy()

    if lookahead_window.empty:
        print(f"  âš ï¸  No operations found within {LOOKAHEAD_HOURS}h window")
        limiters = []
    else:
        total_ct_in_window = lookahead_window['CT_GOAL'].sum()
        print(f"  Found {len(lookahead_window)} operations spanning {total_ct_in_window:.1f}h")

        # Identify limiters
        limiters = []
        if not df_ceid.empty and "CEID" in df_ceid.columns:
            df_ceid["CEID"] = df_ceid["CEID"].astype(str)

        for _, row in lookahead_window.iterrows():
            reasons = []
            ceid = row.get('CEID', 'N/A')
            operation = row.get('OPERATION', 'N/A')
            oper_desc = row.get('OPER_SHORT_DESC', 'N/A')
            ct_goal = safe_num(row.get('CT_GOAL', 0.0), 0.0)
            avg_hao = safe_num(row.get('AVG_HAO', np.nan), np.nan)
            max_hao = safe_num(row.get('MAX_HAO', np.nan), np.nan)
            inv_prod = safe_num(row.get('INV_PROD', np.nan), np.nan)
            inv_goal = safe_num(row.get('INV_GOAL', np.nan), np.nan)

            if not math.isnan(avg_hao) and avg_hao > ct_goal:
                reasons.append(f"AVG_HAO ({avg_hao:.2f}h) > CT_GOAL ({ct_goal:.2f}h)")
            if not math.isnan(inv_prod) and not math.isnan(inv_goal) and inv_prod > inv_goal:
                reasons.append(f"INV_PROD ({inv_prod:.0f}w) > INV_GOAL ({inv_goal:.0f}w)")
            if not math.isnan(avg_hao) and avg_hao > ct_goal + LIMITER_HAO_VARIANCE:
                reasons.append(f"AVG_HAO > CT_GOAL+{LIMITER_HAO_VARIANCE:.1f}h")
            if not math.isnan(max_hao) and max_hao > ct_goal + LIMITER_HAO_VARIANCE:
                reasons.append(f"MAX_HAO > CT_GOAL+{LIMITER_HAO_VARIANCE:.1f}h")

            # CEID WSPW pace gap
            if not df_ceid.empty and ceid is not None and not pd.isna(ceid):
                ceid_row = df_ceid[df_ceid['CEID'] == str(ceid)]
                if not ceid_row.empty:
                    cs_wspw_pace = ceid_row['CS_WSPW_PACE'].values[0] if 'CS_WSPW_PACE' in ceid_row.columns else None
                    wse_goal = ceid_row['WSE_GOAL'].values[0] if 'WSE_GOAL' in ceid_row.columns else None
                    if cs_wspw_pace is not None and wse_goal is not None:
                        try:
                            pace_gap = float(wse_goal) - float(cs_wspw_pace)
                            if pace_gap >= LIMITER_WSPW_GAP:
                                reasons.append(f"WSPW pace {pace_gap:.0f} below goal")
                        except Exception:
                            pass

            if reasons:
                limiters.append({
                    'CEID': ceid,
                    'OPERATION': operation,
                    'OPER_SHORT_DESC': oper_desc,
                    'SEGMENT_DAY': row.get('SEGMENT_DAY', 0),
                    'CT_GOAL': ct_goal,
                    'AVG_HAO': avg_hao,
                    'MAX_HAO': max_hao,
                    'INV_PROD': inv_prod,
                    'INV_GOAL': inv_goal,
                    'REASONS': ' | '.join(reasons)
                })
else:
    print(f"  âš ï¸  CT_GOAL column not found in LineView")
    lookahead_window = pd.DataFrame()
    limiters = []

# =============================================================================
# OUTPUT REPORT
# =============================================================================
print(f"""
{'='*110}
Q4 PRODUCTION CONTROL DASHBOARD  |  Timestamp: {now:%Y-%m-%d %H:%M:%S}  |  Current Week: WW{COMMIT_WW}
{'='*110}

QUARTERLY COMMIT STATUS:
  Q4 Ships Goal:                            {fmt_int(QUARTER_GOAL)} w
  Shipped to Date:                          {fmt_int(quarter_ships)} w  ({(quarter_ships/QUARTER_GOAL*100 if QUARTER_GOAL else 0):5.1f}%)
  Commit Inventory Remaining:               {fmt_int(commit_inventory_remaining)} w  ({(commit_inventory_remaining/QUARTER_GOAL*100 if QUARTER_GOAL else 0):5.1f}%)

PRODUCTION POINT (PP) - QUARTERLY:
  PP Ships Location (SD/OP/FLS):            SD{pp_segment_day} | {fmt_int(quarter_volume_pp['OPERATION'].values[0])} | {fmt_int(pp_full_loop_seq)}
  Bump Inventory from PP:                   {fmt_int(quarter_bump_inv)} w
  Segment Days (PP â†’ SD{SEGMENT_DAY_END}) [exclusive]: {fmt_int(segment_days_remaining)} SD
  Q4 Ships Goal Required (PP â†’ SD{SEGMENT_DAY_END}):    {fmt_int(quarter_outs_remaining)} w

SCHEDULE ANALYSIS:
  Calendar Days Remaining:                  {fmt_int(calendar_days_remaining)} days
  Segment Days Remaining:                   {fmt_int(segment_days_remaining)} SD
  Commit Ahead/Behind:                      {commit_ahead_behind_days:+} days {'âœ“ AHEAD' if commit_ahead_behind_days >= 0 else 'âŒ BEHIND'}

WIP & INVENTORY:
  Total WIP in Fab:                         {fmt_int(total_current_wip)} w
  Last 24hr Inventory Reduction:            {fmt_int(last_24hr_inv_reduction)} w

REQUIRED OUTPUT RATES (Q4 QUARTERLY):
  Shiftly Min Outs to Hit Q4 Goal:          {fmt_float(required_per_shift, 1)} w/shift (12h)
  Daily Min Outs to Hit Q4 Goal:            {fmt_float(required_per_day, 1)} w/day
  Weekly Min Outs to Hit Q4 Goal:           {fmt_float(required_per_week, 1)} w/week
""")

if rate_gap is not None:
    print(f"""
RATE ANALYSIS (Q4):
  Historical Avg Rate:                      {fmt_float(actual_daily_rate, 1)} w/day
  Required Rate:                            {fmt_float(required_per_day, 1)} w/day
  Rate Gap:                                 {fmt_float(rate_gap, 1)} w/day ({('+' if rate_gap_pct is not None and rate_gap_pct>=0 else '') + (f'{rate_gap_pct:.1f}%' if rate_gap_pct is not None else 'â€”')})
  Status:                                   {'âœ“ ON TRACK' if on_track else 'âŒ MUST ACCELERATE'}
""")

print(f"""
{'='*110}
WEEKLY PERFORMANCE & TRACKING
{'='*110}

LAST WEEK (WW{last_ww}):
  Shipped:                                  {fmt_int(last_week_ships)} w
  Goal:                                     {fmt_int(OUTS_GOAL)} w
  Status:                                   {'âœ“ MET GOAL' if last_week_ships >= OUTS_GOAL else f'âŒ MISSED by {fmt_int(OUTS_GOAL - last_week_ships)} w'}

CURRENT WEEK (WW{COMMIT_WW}):
  Base Weekly Goal:                         {fmt_int(OUTS_GOAL)} w
  Catch-up from Last Week:                  {fmt_int(last_week_shortfall)} w
  THIS WEEK REQUIRED TOTAL:                 {fmt_int(this_week_required)} w  {'âš ï¸  INCREASED' if last_week_shortfall > 0 else ''}

  Shipped This Week (so far):               {fmt_int(current_week_outs)} w  ({(current_week_outs/this_week_required*100 if this_week_required else 0):5.1f}%)
  Still Need to Ship This Week:             {fmt_int(outs_remaining_this_week)} w

  Days Left in Week:                        {fmt_int(days_left_in_week)} days
  Shifts Left in Week:                      {fmt_int(shifts_left_in_week)} shifts

  Required per Shift (remaining):           {fmt_float(this_week_per_shift, 1)} w/shift
  Required per Day (remaining):             {fmt_float(this_week_per_day, 1)} w/day
""")

print("WEEK PP (Current Week):")
if not pp_operation.empty:
    try:
        preview = pp_operation.filter(['SEGMENT_DAY', 'OPER_SHORT_DESC', 'CEID']).to_string(index=False, header=True)
        print(preview)
    except Exception:
        print("  (PP operation data available but could not render table.)")
else:
    print("  N/A")

print(f"""
NEXT WEEK PROJECTION (WW{next_ww}):
  Current Week Daily Rate:                  {fmt_float(current_week_daily_rate, 1)} w/day
  Projected Ships:                          {fmt_int(next_ww_projected_ships)} w
""")

# =============================================================================
# LIMITER ANALYSIS OUTPUT
# =============================================================================
print(f"""
{'='*110}
TOOL LIMITER ANALYSIS ({LOOKAHEAD_HOURS}h Look-Ahead from PP)
{'='*110}
Look-Ahead Configuration:
  Hours Ahead:                              {fmt_float(LOOKAHEAD_HOURS, 0)} h
  Layer Count Threshold:                    {LAYER_COUNT_THRESHOLD} (exclude < {LAYER_COUNT_THRESHOLD*100:.0f}%)
  HAO Variance Threshold:                   {LIMITER_HAO_VARIANCE} h
  WSPW Pace Gap Threshold:                  {LIMITER_WSPW_GAP}
""")

if limiters:
    print(f"{'âš ï¸  LIMITERS IDENTIFIED:':<40} {fmt_int(len(limiters))} tool(s)\n")
    print(f"{'CEID':<12} {'Operation':<10} {'Description':<22} {'SD':<5} {'CT':<8} {'AVG':<8} {'INV':<8} {'Limiter Reasons'}")
    print("-" * 140)
    for lim in limiters:
        print(f"{str(lim['CEID'])[:12]:<12} {str(lim['OPERATION'])[:10]:<10} {str(lim['OPER_SHORT_DESC'])[:22]:<22} "
              f"{fmt_int(lim.get('SEGMENT_DAY', 0)):<5} {fmt_float(lim.get('CT_GOAL', 0.0),1):<8} {fmt_float(lim.get('AVG_HAO', 0.0),1):<8} "
              f"{fmt_int(lim.get('INV_PROD', 0)):<8} {lim['REASONS']}")
else:
    print("âœ“ No limiters identified in look-ahead window")

print(f"\n{'='*110}\n")
