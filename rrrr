The way the app should work, all configurations should be entered manually and a user should be able to save their previos configurations in local storage so it is easy to go back to and they can still change it if need be. 
also, some CEIDs can appear as a limiter more than once so let it show up once in the the table, but with a count next to it and if the user hovers over it, all its reasons should show. 
please make this is a way that i can just copy the html file, css and python file or if there is a simpler way, go ahead.  


#SAFFI
import pandas as pd
import PyUber
from datetime import datetime, timedelta
import numpy as np
from pathlib import Path

# Configuration
OUTS_GOAL = 8100
QUARTER_GOAL = 96915
DEADLINE = datetime(2025, 12, 3, 23, 59, 59)
QUARTER_START = datetime(2025, 9, 6, 18, 0)
COMMIT_WW = 202549
SSAFI_LSB_OPERATION = 9812
SEGMENT_DAY_END = 104

# Look-ahead Configuration
LOOKAHEAD_HOURS = 24
LOOKAHEAD_FROM_SD = 79              # Segment Day to start look-ahead from (used if LOOKAHEAD_FROM_OPERATION is None)
LOOKAHEAD_FROM_OPERATION = 193269     # Specific operation to start from (set to None to use SD instead)
LAYER_COUNT_THRESHOLD = 0.30
LIMITER_HAO_VARIANCE = 3.5
LIMITER_WSPW_GAP = 500
LIMITER_UP_THRESHOLD = 0.10
LIMITER_ROADS_THRESHOLD = 0.10

# 24/7 Operation Parameters
SHIFTS_PER_DAY = 2
HOURS_PER_SHIFT = 12
DAYS_PER_WEEK = 7

LINEVIEW_PATH = r"\\azshfs.intel.com\azanalysistop\AZAnalysis\1274_MAODATA\AZFSM_Production\COS_DB\Combined\LineView.TXT"
CEID_PATH = r"\\azshfs.intel.com\azanalysistop\AZAnalysis\1274_MAODATA\AZFSM_Production\COS_DB\Combined\CEID.TXT"
EXCLUDED_OPERATIONS = [204]

def load_lineview_with_validation(path):
    """Load LineView with data freshness check"""
    try:
        file_path = Path(path)
        if not file_path.exists():
            raise FileNotFoundError(f"LineView not accessible at {path}")
        
        mod_time = datetime.fromtimestamp(file_path.stat().st_mtime)
        age_hours = (datetime.now() - mod_time).total_seconds() / 3600
        
        if age_hours > 2:
            print(f"‚ö†Ô∏è  WARNING: LineView data is {age_hours:.1f} hours old")
        
        df = pd.read_csv(path, sep="\t")
        print(f"‚úì LineView loaded: {len(df)} operations, updated {age_hours:.1f}h ago")
        return df
    
    except Exception as e:
        print(f"‚ùå Error loading LineView: {e}")
        raise

def load_ceid_data(path):
    """Load CEID data for limiter analysis"""
    try:
        file_path = Path(path)
        if not file_path.exists():
            print(f"‚ö†Ô∏è  WARNING: CEID file not accessible at {path}")
            return pd.DataFrame()
        
        df = pd.read_csv(path, sep="\t")
        print(f"‚úì CEID data loaded: {len(df)} CEIDs")
        return df
    
    except Exception as e:
        print(f"‚ö†Ô∏è  Could not load CEID data: {e}")
        return pd.DataFrame()

# ============================================================================
# LOAD DATA
# ============================================================================
df_lineview = load_lineview_with_validation(LINEVIEW_PATH)
df_ceid = load_ceid_data(CEID_PATH)
now = datetime.now()

# Get SSAFI LSB Full Loop Sequence
try:
    ssafi_lsb_fls = df_lineview.loc[
        df_lineview["OPERATION"] == SSAFI_LSB_OPERATION, 
        "FULL_LOOP_SEQ"
    ].values[0]
except IndexError:
    raise ValueError(f"Operation {SSAFI_LSB_OPERATION} not found in LineView")

# ============================================================================
# GET QUARTERLY SHIPMENTS
# ============================================================================
quarter_ships_sql = f'''
SELECT
  SUM(WAFER_QTY) as total_wafers,
  COUNT(DISTINCT LOT) as lot_count,
  MAX(OUT_DATE) as last_ship_date,
  MIN(OUT_DATE) as first_ship_date
FROM
  F_LOT_RUN_CARD
WHERE
  OUT_DATE >= TO_DATE('{QUARTER_START.strftime("%m/%d/%Y %H:%M")}', 'MM/DD/YYYY HH24:MI')
  AND OUT_DATE <= SYSDATE
  AND LOT_TYPE IN ('PROD', 'ENG')
  AND LOT LIKE 'L%'
  AND LOT NOT LIKE 'L9%'
  AND OPERATION = {SSAFI_LSB_OPERATION}
  AND WAFER_QTY > 0
'''

try:
    quarter_ships_df = pd.read_sql(quarter_ships_sql, PyUber.connect('F32_PROD_XEUS'))
    quarter_ships = quarter_ships_df['TOTAL_WAFERS'].values[0]
    
    if pd.isna(quarter_ships) or quarter_ships == 0:
        quarter_ships = 0
        print("‚ö†Ô∏è  WARNING: No quarter shipments found")
    else:
        lot_count = quarter_ships_df['LOT_COUNT'].values[0]
        last_ship = quarter_ships_df['LAST_SHIP_DATE'].values[0]
        first_ship = quarter_ships_df['FIRST_SHIP_DATE'].values[0]
        
        days_elapsed = (pd.to_datetime(last_ship) - pd.to_datetime(first_ship)).days + 1
        actual_daily_rate = quarter_ships / days_elapsed if days_elapsed > 0 else 0
        
        print(f"‚úì Quarter ships: {quarter_ships:,.0f}w from {lot_count} lots")
        print(f"  Period: {first_ship} to {last_ship} ({days_elapsed} days)")
        print(f"  Actual rate: {actual_daily_rate:.0f}w/day")
        
except Exception as e:
    print(f"‚ùå Database error: {e}")
    raise

# ============================================================================
# GET LAST WEEK'S SHIPMENTS
# ============================================================================
last_ww = COMMIT_WW - 1
today = now.date()
days_since_monday = today.weekday()
current_week_start = today - timedelta(days=days_since_monday)
last_week_start = current_week_start - timedelta(days=7)

last_week_sql = f'''
SELECT
  SUM(WAFER_QTY) as total_wafers
FROM
  F_LOT_RUN_CARD
WHERE
  OUT_DATE >= TO_DATE('{last_week_start.strftime("%m/%d/%Y")} 00:00', 'MM/DD/YYYY HH24:MI')
  AND OUT_DATE < TO_DATE('{current_week_start.strftime("%m/%d/%Y")} 00:00', 'MM/DD/YYYY HH24:MI')
  AND LOT_TYPE IN ('PROD', 'ENG')
  AND LOT LIKE 'L%'
  AND LOT NOT LIKE 'L9%'
  AND OPERATION = {SSAFI_LSB_OPERATION}
  AND WAFER_QTY > 0
'''

try:
    last_week_df = pd.read_sql(last_week_sql, PyUber.connect('F32_PROD_XEUS'))
    last_week_ships = last_week_df['TOTAL_WAFERS'].values[0]
    
    if pd.isna(last_week_ships):
        last_week_ships = 0
        
    print(f"‚úì Last week (WW{last_ww}) ships: {last_week_ships:,.0f}w")
    
except Exception as e:
    print(f"‚ö†Ô∏è  Could not retrieve last week shipments: {e}")
    last_week_ships = 0

last_week_shortfall = max(0, OUTS_GOAL - last_week_ships)
last_week_status = "‚úì MET GOAL" if last_week_ships >= OUTS_GOAL else f"‚ùå MISSED by {last_week_shortfall:,.0f}w"

this_week_required = OUTS_GOAL + last_week_shortfall

# ============================================================================
# CALCULATE KEY METRICS
# ============================================================================
quarter_outs_remaining = QUARTER_GOAL - quarter_ships
commit_inventory_remaining = quarter_outs_remaining

total_hours_remaining = (DEADLINE - now).total_seconds() / 3600
calendar_days_remaining = (DEADLINE - now).days + 1
total_shifts_remaining = calendar_days_remaining * SHIFTS_PER_DAY

print(f"\n‚è∞ Time remaining: {calendar_days_remaining} days = {total_hours_remaining:.1f} hours = {total_shifts_remaining} shifts")

# ============================================================================
# QUARTERLY PP CALCULATION
# ============================================================================
quarter_volume = (df_lineview
                  .query(f"FULL_LOOP_SEQ <= {ssafi_lsb_fls} & OPERATION not in {EXCLUDED_OPERATIONS}")
                  .assign(PP_INV=lambda x: x.iloc[::-1]['INV_PROD'].cumsum()[::-1],
                          PP_W=lambda x: x["PP_INV"] // quarter_outs_remaining,
                          PP_mod=lambda x: x["PP_INV"] % quarter_outs_remaining)
                  )

quarter_volume_pp = quarter_volume.query("PP_W == 1").tail(1)

if not quarter_volume.query("PP_W == 0").empty:
    quarter_bump_inv = quarter_outs_remaining - quarter_volume.query("PP_W == 0").head(1).filter(["PP_mod"]).values[0][0]
else:
    quarter_bump_inv = 0

if quarter_volume_pp.empty:
    total_wip = quarter_volume['INV_PROD'].sum()
    print(f"\n‚ùå CRITICAL: Insufficient WIP to meet quarterly goal!")
    print(f"   Total WIP: {total_wip:,.0f}w | Need: {quarter_outs_remaining:,.0f}w | Short: {quarter_outs_remaining - total_wip:,.0f}w")
    quarter_volume_pp = quarter_volume.tail(1)

pp_segment_day = quarter_volume_pp['SEGMENT_DAY'].values[0] if not quarter_volume_pp.empty else 0
pp_full_loop_seq = quarter_volume_pp['FULL_LOOP_SEQ'].values[0] if not quarter_volume_pp.empty else 0
segment_days_remaining = SEGMENT_DAY_END - pp_segment_day
commit_ahead_behind_days = calendar_days_remaining - segment_days_remaining

# ============================================================================
# FIND STARTING POINT FOR LOOK-AHEAD (OPERATION OR SD)
# ============================================================================
lookahead_start_ops = df_lineview.query(
    f"FULL_LOOP_SEQ <= {ssafi_lsb_fls} & OPERATION not in {EXCLUDED_OPERATIONS}"
).copy()

if not lookahead_start_ops.empty:
    # Check if user specified an operation number
    if LOOKAHEAD_FROM_OPERATION is not None:
        # Look for the specific operation
        lookahead_op_match = lookahead_start_ops[lookahead_start_ops['OPERATION'] == LOOKAHEAD_FROM_OPERATION]
        
        if not lookahead_op_match.empty:
            lookahead_start_op = lookahead_op_match.iloc[0]
            lookahead_method = f"Operation {LOOKAHEAD_FROM_OPERATION}"
            print(f"\nüîç Look-ahead starting from specified operation: {LOOKAHEAD_FROM_OPERATION}")
        else:
            print(f"\n‚ö†Ô∏è  WARNING: Operation {LOOKAHEAD_FROM_OPERATION} not found, falling back to SD{LOOKAHEAD_FROM_SD}")
            # Fall back to SD method
            lookahead_start_ops['SD_DIFF'] = abs(lookahead_start_ops['SEGMENT_DAY'] - LOOKAHEAD_FROM_SD)
            lookahead_start_op = lookahead_start_ops.loc[lookahead_start_ops['SD_DIFF'].idxmin()]
            lookahead_method = f"SD{LOOKAHEAD_FROM_SD} (fallback)"
            print(f"üîç Look-ahead starting from closest SD: SD{lookahead_start_op['SEGMENT_DAY']:.0f}")
    else:
        # Use SD-based lookup
        lookahead_start_ops['SD_DIFF'] = abs(lookahead_start_ops['SEGMENT_DAY'] - LOOKAHEAD_FROM_SD)
        lookahead_start_op = lookahead_start_ops.loc[lookahead_start_ops['SD_DIFF'].idxmin()]
        lookahead_method = f"SD{LOOKAHEAD_FROM_SD}"
        print(f"\nüîç Look-ahead starting from segment day: SD{lookahead_start_op['SEGMENT_DAY']:.0f}")
    
    lookahead_start_fls = lookahead_start_op['FULL_LOOP_SEQ']
    lookahead_actual_sd = lookahead_start_op['SEGMENT_DAY']
    lookahead_start_operation = lookahead_start_op['OPERATION']
    lookahead_start_ceid = lookahead_start_op.get('CEID', 'N/A')
    lookahead_start_desc = lookahead_start_op.get('OPER_SHORT_DESC', 'N/A')
    
    print(f"   Operation: {lookahead_start_operation} | {lookahead_start_desc} | {lookahead_start_ceid} | SD{lookahead_actual_sd:.0f}")
else:
    print(f"\n‚ö†Ô∏è  WARNING: Could not find starting point for look-ahead, using PP location")
    lookahead_start_fls = pp_full_loop_seq
    lookahead_actual_sd = pp_segment_day
    lookahead_start_operation = "PP"
    lookahead_method = "PP (fallback)"

# ============================================================================
# LOOK-AHEAD ANALYSIS FROM CONFIGURED STARTING POINT
# ============================================================================
print(f"\nüîç Analyzing {LOOKAHEAD_HOURS}h look-ahead from {lookahead_method}...")

lookahead_ops = df_lineview.query(
    f"FULL_LOOP_SEQ > {lookahead_start_fls} & FULL_LOOP_SEQ <= {ssafi_lsb_fls} & OPERATION not in {EXCLUDED_OPERATIONS}"
).copy()

if 'LAYER_COUNT' in lookahead_ops.columns:
    lookahead_ops = lookahead_ops.query(f"LAYER_COUNT >= {LAYER_COUNT_THRESHOLD}")
    print(f"  Filtered to operations with LAYER_COUNT >= {LAYER_COUNT_THRESHOLD}")

if 'CT_GOAL' in lookahead_ops.columns:
    lookahead_ops['CUMULATIVE_CT'] = lookahead_ops['CT_GOAL'].cumsum()
    lookahead_window = lookahead_ops.query(f"CUMULATIVE_CT <= {LOOKAHEAD_HOURS}")
    
    if lookahead_window.empty:
        print(f"  ‚ö†Ô∏è  No operations found within {LOOKAHEAD_HOURS}h window")
    else:
        total_ct_in_window = lookahead_window['CT_GOAL'].sum()
        print(f"  Found {len(lookahead_window)} operations spanning {total_ct_in_window:.1f}h")
        
        # ====================================================================
        # IDENTIFY LIMITERS IN LOOKAHEAD WINDOW
        # ====================================================================
        limiters = []
        
        for idx, row in lookahead_window.iterrows():
            limiter_reasons = []
            ceid = row.get('CEID', 'N/A')
            operation = row.get('OPERATION', 'N/A')
            oper_desc = row.get('OPER_SHORT_DESC', 'N/A')
            fist = row.get('FIST', 'N/A')
            if pd.isna(fist):
                fist = 'N/A'
            
            ct_goal = row.get('CT_GOAL', 0)
            avg_hao = row.get('AVG_HAO', 0)
            max_hao = row.get('MAX_HAO', 0)
            inv_prod = row.get('INV_PROD', 0)
            inv_goal = row.get('INV_GOAL', 0)
            
            # Limiter Criterion 1: AVG_HAO > CT_GOAL
            if pd.notna(avg_hao) and pd.notna(ct_goal) and avg_hao > ct_goal:
                limiter_reasons.append(f"AVG_HAO ({avg_hao:.2f}h) > CT_GOAL ({ct_goal:.2f}h)")
            
            # Limiter Criterion 2: INV_PROD > INV_GOAL
            if pd.notna(inv_prod) and pd.notna(inv_goal) and inv_prod > inv_goal:
                limiter_reasons.append(f"INV_PROD ({inv_prod:.0f}w) > INV_GOAL ({inv_goal:.0f}w)")
            
            # Limiter Criterion 3: Both AVG_HAO and MAX_HAO are 3.5h+ over CT_GOAL
            if (pd.notna(avg_hao) and pd.notna(max_hao) and pd.notna(ct_goal) and 
                avg_hao > ct_goal + LIMITER_HAO_VARIANCE and 
                max_hao > ct_goal + LIMITER_HAO_VARIANCE):
                limiter_reasons.append(f"AVG_HAO & MAX_HAO both >{LIMITER_HAO_VARIANCE:.1f}h over CT_GOAL")
            
            # Check CEID data for additional limiter criteria
            if not df_ceid.empty and pd.notna(ceid):
                ceid_row = df_ceid[df_ceid['CEID'] == ceid]
                if not ceid_row.empty:
                    cs_wspw_pace = ceid_row['CS_WSPW_PACE'].values[0] if 'CS_WSPW_PACE' in ceid_row.columns else None
                    wse_goal = ceid_row['WSE_GOAL'].values[0] if 'WSE_GOAL' in ceid_row.columns else None
                    
                    if pd.notna(cs_wspw_pace) and pd.notna(wse_goal):
                        pace_gap = wse_goal - cs_wspw_pace
                        if pace_gap >= LIMITER_WSPW_GAP:
                            limiter_reasons.append(f"WSPW pace {pace_gap:.0f} below goal")
                    
                    up = ceid_row['UP'].values[0] if 'UP' in ceid_row.columns else None
                    tool_reqd = ceid_row['TOOL_REQD'].values[0] if 'TOOL_REQD' in ceid_row.columns else None
                    
                    if pd.notna(up) and pd.notna(tool_reqd) and tool_reqd > 0:
                        up_percent = up / tool_reqd
                        if up_percent < LIMITER_UP_THRESHOLD:
                            limiter_reasons.append(f"UP ({up:.1f}) < {LIMITER_UP_THRESHOLD*100:.0f}% of TOOL_REQD ({tool_reqd:.1f})")
                    
                    hr24_wspw_pace = ceid_row['HR24_WSPW_PACE'].values[0] if 'HR24_WSPW_PACE' in ceid_row.columns else None
                    roads = ceid_row['ROADS'].values[0] if 'ROADS' in ceid_row.columns else None
                    
                    if pd.notna(hr24_wspw_pace) and pd.notna(roads) and roads > 0:
                        roads_threshold = roads * (1 - LIMITER_ROADS_THRESHOLD)
                        if hr24_wspw_pace < roads_threshold:
                            percent_below = ((roads - hr24_wspw_pace) / roads) * 100
                            limiter_reasons.append(f"HR24_WSPW_PACE ({hr24_wspw_pace:.0f}) {percent_below:.1f}% below ROADS ({roads:.0f})")
            
            if limiter_reasons:
                limiters.append({
                    'CEID': ceid,
                    'OPERATION': operation,
                    'OPER_SHORT_DESC': oper_desc,
                    'FIST': fist,
                    'SEGMENT_DAY': row.get('SEGMENT_DAY', 0),
                    'CT_GOAL': ct_goal,
                    'AVG_HAO': avg_hao,
                    'MAX_HAO': max_hao,
                    'INV_PROD': inv_prod,
                    'INV_GOAL': inv_goal,
                    'REASONS': ' | '.join(limiter_reasons)
                })
        
        print(f"  Identified {len(limiters)} limiter(s) in {LOOKAHEAD_HOURS}h window")
        
else:
    print(f"  ‚ö†Ô∏è  CT_GOAL column not found in LineView")
    lookahead_window = pd.DataFrame()
    limiters = []

# ============================================================================
# INVENTORY ANALYSIS
# ============================================================================
total_current_wip = df_lineview['INV_PROD'].sum()

if 'PW_OUTS_PROD' in df_lineview.columns:
    pw_outs = df_lineview.loc[df_lineview["OPERATION"] == SSAFI_LSB_OPERATION, "PW_OUTS_PROD"].values[0]
    last_24hr_inv_reduction = pw_outs / 7
else:
    last_24hr_inv_reduction = actual_daily_rate if 'actual_daily_rate' in locals() else 0

# ============================================================================
# GET CURRENT SHIFT AND WEEK PACE
# ============================================================================
current_shift_outs = df_lineview.loc[
    df_lineview["OPERATION"] == SSAFI_LSB_OPERATION, 
    "CS_OUTS_PROD"
].values[0] if 'CS_OUTS_PROD' in df_lineview.columns else 0

current_week_outs = df_lineview.loc[
    df_lineview["OPERATION"] == SSAFI_LSB_OPERATION, 
    "CW_OUTS_PROD"
].values[0]

# Calculate pace (wafers per hour)
current_shift_pace = current_shift_outs / HOURS_PER_SHIFT if current_shift_outs > 0 else 0
current_week_pace = current_week_outs / (days_since_monday + 1) / 24 if (days_since_monday + 1) > 0 else 0

# ============================================================================
# WEEKLY PP CALCULATION
# ============================================================================
outs_remaining_this_week = this_week_required - current_week_outs

pp = (df_lineview
      .query(f"FULL_LOOP_SEQ <= {ssafi_lsb_fls} & OPERATION not in {EXCLUDED_OPERATIONS}")
      .filter(["SEGMENT_DAY", "OPERATION", "OPER_SHORT_DESC", "CEID", "INV_PROD"])
      .assign(PP_INV=lambda x: x.iloc[::-1]['INV_PROD'].cumsum()[::-1],
              PP_W=lambda x: x["PP_INV"] // outs_remaining_this_week if outs_remaining_this_week > 0 else 0,
              PP_mod=lambda x: x["PP_INV"] % outs_remaining_this_week if outs_remaining_this_week > 0 else 0)
      .query("PP_W == 1 & INV_PROD != 0")
      )

pp_operation = pp.query(f"PP_mod == {pp['PP_mod'].min()}") if not pp.empty else pd.DataFrame()

pp_before = (df_lineview
             .query(f"FULL_LOOP_SEQ <= {ssafi_lsb_fls} & OPERATION not in {EXCLUDED_OPERATIONS}")
             .filter(["SEGMENT_DAY", "OPERATION", "OPER_SHORT_DESC", "CEID", "INV_PROD"])
             .assign(PP_INV=lambda x: x.iloc[::-1]['INV_PROD'].cumsum()[::-1],
                     PP_W=lambda x: x["PP_INV"] // outs_remaining_this_week if outs_remaining_this_week > 0 else 0,
                     PP_mod=lambda x: x["PP_INV"] % outs_remaining_this_week if outs_remaining_this_week > 0 else 0)
             .query("PP_W == 0 & INV_PROD != 0")
             )

bump_inv = outs_remaining_this_week - pp_before["PP_INV"].head(1).values[0] if not pp_before.empty and outs_remaining_this_week > 0 else 0

# ============================================================================
# CALCULATE REQUIRED RATES
# ============================================================================
required_per_day = quarter_outs_remaining / calendar_days_remaining if calendar_days_remaining > 0 else 0
required_per_shift = required_per_day / SHIFTS_PER_DAY
required_per_week = required_per_day * 7
required_per_hour = required_per_day / 24

q4_shiftly_outs_required = required_per_shift
q4_weekly_min_outs = required_per_week

days_left_in_week = 7 - now.weekday()
hours_left_in_week = days_left_in_week * 24 - now.hour
shifts_left_in_week = max(1, int(hours_left_in_week / HOURS_PER_SHIFT))

this_week_per_shift = outs_remaining_this_week / shifts_left_in_week if shifts_left_in_week > 0 else 0
this_week_per_day = outs_remaining_this_week / days_left_in_week if days_left_in_week > 0 else 0

# ============================================================================
# NEXT WEEK PROJECTION
# ============================================================================
days_into_week = now.weekday() + 1
if days_into_week > 0:
    current_week_daily_rate = current_week_outs / days_into_week
else:
    current_week_daily_rate = actual_daily_rate if 'actual_daily_rate' in locals() else 0

next_ww = COMMIT_WW + 1
next_ww_projected_ships = current_week_daily_rate * 7

if 'actual_daily_rate' in locals() and actual_daily_rate > 0:
    rate_gap = required_per_day - actual_daily_rate
    rate_gap_pct = (rate_gap / actual_daily_rate) * 100
    on_track = rate_gap <= 0
else:
    rate_gap = None
    on_track = None

# ============================================================================
# OUTPUT REPORT
# ============================================================================
print(f"""
{'='*100}
Q4 PRODUCTION CONTROL DASHBOARD - 24/7 OPERATION
Timestamp: {now.strftime('%Y-%m-%d %H:%M:%S')} | Current Week: WW{COMMIT_WW}
{'='*100}

QUARTERLY COMMIT STATUS:
  Q4 Ships Goal:                            {QUARTER_GOAL:>10,}w
  Shipped to Date:                          {quarter_ships:>10,.0f}w  ({(quarter_ships/QUARTER_GOAL)*100:>5.1f}%)
  Commit Inventory Remaining:               {commit_inventory_remaining:>10,.0f}w  ({(commit_inventory_remaining/QUARTER_GOAL)*100:>5.1f}%)
  
PRODUCTION POINT (PP) - QUARTERLY:
  PP Ships Location:                        {quarter_volume_pp.filter(['SEGMENT_DAY', 'OPERATION', 'OPER_SHORT_DESC', 'CEID']).to_string(index=False, header=False) if not quarter_volume_pp.empty else 'N/A'}
  Bump Inventory from PP:                   {quarter_bump_inv:>10,.0f}w
  Segment Days (PP ‚Üí SD{SEGMENT_DAY_END}):              {segment_days_remaining:>10} SD
  Q4 Ships Goal Required (PP ‚Üí SD{SEGMENT_DAY_END}):    {quarter_outs_remaining:>10,.0f}w

SCHEDULE ANALYSIS:
  Calendar Days Remaining:                  {calendar_days_remaining:>10} days
  Segment Days Remaining (PP ‚Üí SD{SEGMENT_DAY_END}):    {segment_days_remaining:>10} SD
  Commit Ahead/Behind:                      {commit_ahead_behind_days:>+10} days {'‚úì AHEAD' if commit_ahead_behind_days >= 0 else '‚ùå BEHIND'}

WIP & INVENTORY:
  Total WIP in Fab:                         {total_current_wip:>10,.0f}w
  Last 24hr Inventory Reduction:            {last_24hr_inv_reduction:>10,.0f}w

CURRENT PACE:
  Current Shift Pace:                       {current_shift_pace:>10.1f}w/hr ({current_shift_outs:>,.0f}w this shift)
  Current Week Pace:                        {current_week_pace:>10.1f}w/hr ({current_week_outs:>,.0f}w this week)

REQUIRED OUTPUT RATES (Q4 QUARTERLY):
  Shiftly Min Outs to Hit Q4 Goal:          {q4_shiftly_outs_required:>10.0f}w/shift (12h)
  Daily Min Outs to Hit Q4 Goal:            {required_per_day:>10.0f}w/day
  Weekly Min Outs to Hit Q4 Goal:           {q4_weekly_min_outs:>10.0f}w/week
""")

if rate_gap is not None:
    print(f"""
RATE ANALYSIS (Q4):
  Historical Avg Rate:                      {actual_daily_rate:>10.1f}w/day
  Required Rate:                            {required_per_day:>10.1f}w/day
  Rate Gap:                                 {rate_gap:>10.1f}w/day ({rate_gap_pct:>+5.1f}%)
  Status:                                   {'‚úì ON TRACK' if on_track else '‚ùå MUST ACCELERATE'}
""")

print(f"""
{'='*100}
WEEKLY PERFORMANCE & TRACKING
{'='*100}

LAST WEEK (WW{last_ww}):
  Shipped:                                  {last_week_ships:>10,.0f}w
  Goal:                                     {OUTS_GOAL:>10,}w
  Status:                                   {last_week_status}
  {'Shortfall to Make Up:                    ' + f'{last_week_shortfall:>10,.0f}w' if last_week_shortfall > 0 else ''}

CURRENT WEEK (WW{COMMIT_WW}):
  Base Weekly Goal:                         {OUTS_GOAL:>10,}w
  Catch-up from Last Week:                  {last_week_shortfall:>+10,.0f}w
  THIS WEEK REQUIRED TOTAL:                 {this_week_required:>10,.0f}w  {'‚ö†Ô∏è  INCREASED' if last_week_shortfall > 0 else ''}
  
  Shipped This Week (so far):               {current_week_outs:>10,.0f}w  ({(current_week_outs/this_week_required)*100:>5.1f}%)
  Still Need to Ship This Week:             {outs_remaining_this_week:>10,.0f}w
  
  Days Left in Week:                        {days_left_in_week:>10} days
  Shifts Left in Week:                      {shifts_left_in_week:>10} shifts
  
  Required per Shift (remaining):           {this_week_per_shift:>10.1f}w/shift
  Required per Day (remaining):             {this_week_per_day:>10.1f}w/day

WEEK PP (Current Week):
  Location:                                 {pp_operation.filter(['SEGMENT_DAY', 'OPER_SHORT_DESC', 'CEID']).to_string(index=False, header=False) if not pp_operation.empty else 'N/A'}
  Bump Inventory from PP:                   {bump_inv:>10,.0f}w

NEXT WEEK PROJECTION (WW{next_ww}):
  Current Week Daily Rate:                  {current_week_daily_rate:>10.1f}w/day
  Projected Ships:                          {next_ww_projected_ships:>10,.0f}w
""")

# ============================================================================
# LIMITER ANALYSIS OUTPUT
# ============================================================================
# Format the starting point for display
if LOOKAHEAD_FROM_OPERATION is not None:
    starting_point_display = f"Operation {lookahead_start_operation} (SD{lookahead_actual_sd:.0f})"
else:
    starting_point_display = f"SD{lookahead_actual_sd:.0f}"

print(f"""
{'='*100}
TOOL LIMITER ANALYSIS ({LOOKAHEAD_HOURS}h Look-Ahead from {starting_point_display})
{'='*100}
Look-Ahead Configuration:
  Starting from:                            {starting_point_display}
  Hours Ahead:                              {LOOKAHEAD_HOURS}h
  Layer Count Threshold:                    {LAYER_COUNT_THRESHOLD} (exclude < {LAYER_COUNT_THRESHOLD*100:.0f}%)
  HAO Variance Threshold:                   {LIMITER_HAO_VARIANCE}h
  WSPW Pace Gap Threshold:                  {LIMITER_WSPW_GAP}
  UP Tool Threshold:                        {LIMITER_UP_THRESHOLD*100:.0f}% of TOOL_REQD
  ROADS Pace Threshold:                     {LIMITER_ROADS_THRESHOLD*100:.0f}% below ROADS
""")

if limiters:
    print(f"\n{'‚ö†Ô∏è  LIMITERS IDENTIFIED:':<50} {len(limiters)} tool(s)\n")
    print(f"{'CEID':<12} {'FIST':<20} {'Operation':<10} {'Description':<20} {'SD':<5} {'CT Goal':<8} {'AVG HAO':<8} {'INV':<8} {'Limiter Reasons'}")
    print("-" * 160)
    for lim in limiters:
        print(f"{str(lim['CEID']):<12} {str(lim['FIST']):<20} {str(lim['OPERATION']):<10} {str(lim['OPER_SHORT_DESC'])[:20]:<20} "
              f"{lim['SEGMENT_DAY']:<5.0f} {lim['CT_GOAL']:<8.2f} {lim['AVG_HAO']:<8.2f} "
              f"{lim['INV_PROD']:<8.0f} {lim['REASONS']}")
else:
    print("\n‚úì No limiters identified in look-ahead window")

print(f"\n{'='*100}")
